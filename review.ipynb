{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e96e6b7-2c69-437e-80c7-6e8efd920751",
   "metadata": {},
   "source": [
    "Chrome version: 130.0.6723.70\n",
    "Chrome Driver Path: /usr/local/bin\n",
    "\n",
    "sudo /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9223 --user-data-dir='~/ChromeProfile'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93981747-cd84-4814-a4c7-0664e8bbfa09",
   "metadata": {},
   "source": [
    "### 0. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba810b4-e4cc-488f-9bf8-bee3c1a6f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bd48ef-236f-44c5-9ce7-dac435d245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db823c5f-cdcb-4b07-969c-77f9c26385a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\")\n",
    "chrome_options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9221\")\n",
    "chrome_driver = \"/Applications/Google\\ Chrome.app/Contents/MacOS/Google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4855af8-53ac-4c14-bbc9-ddd4a2a2977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (130.0.6723.69) detected in PATH at /usr/local/bin/chromedriver might not be compatible with the detected chrome version (131.0.6778.109); currently, chromedriver 131.0.6778.108 is recommended for chrome 131.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "services = ChromeService(executable_path = chrome_driver)\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c834845-4c60-4a3f-853f-7d5d64cacb10",
   "metadata": {},
   "source": [
    "### 2. 각 회사의 Review 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd3b88-ff60-448e-9595-8bf9a37031d7",
   "metadata": {},
   "source": [
    "##### 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844a578f-e862-4bf1-98fa-7bac8337922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_event_time = 5\n",
    "click_event_time = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bafd22-6422-4c27-9ea1-89f8f78940b8",
   "metadata": {},
   "source": [
    "##### 1. 회사 검색 및 리뷰창 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77682d34-af55-407c-b88d-d33b26b7977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_url(company_name):\n",
    "    \n",
    "    \"\"\" Search Company and Get Review page \"\"\"\n",
    "\n",
    "    base_url = 'https://www.glassdoor.com/Reviews/index.htm?overall_rating_low=3.5&page=1&locId=1147401&locType=C&occ=Data%20Scientist'\n",
    "    driver.get(base_url)\n",
    "    time.sleep(link_event_time)\n",
    "\n",
    "    try:\n",
    "        # Locate and input the company name in the search bar\n",
    "        search_xpath = '//*[@id=\"companyAutocomplete-companyDiscover-employerSearch\"]'\n",
    "        search_element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, search_xpath)))\n",
    "        search_element.send_keys(company_name)\n",
    "        time.sleep(click_event_time)\n",
    "\n",
    "        # Click search button\n",
    "        button_xpath = '//*[@id=\"Explore\"]/div[2]/div/div/div[2]/button'\n",
    "        driver.find_element(By.XPATH, button_xpath).click()\n",
    "        time.sleep(click_event_time)\n",
    "\n",
    "        # Click first result link\n",
    "        search_list_xpath = '//*[@id=\"Discover\"]/div/div/div[1]/div[1]/div[1]'\n",
    "        first_result = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, search_list_xpath))\n",
    "        )\n",
    "        first_result_link = first_result.find_elements(By.CSS_SELECTOR, 'a')[0].get_attribute('href')\n",
    "        driver.get(first_result_link)\n",
    "        time.sleep(click_event_time)\n",
    "\n",
    "        # Go to reviews page\n",
    "        a_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#reviews > a')))\n",
    "        review_href = a_element.get_attribute('href')\n",
    "        return review_href\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating to search URL for {company_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a118f5-24df-4f61-b1d6-54d69dc46778",
   "metadata": {},
   "source": [
    "##### 2. 마지막 Review page 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c2f609-7c54-4c74-a201-a3f6eb68a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_page():\n",
    "\n",
    "    \"\"\" Get Last Review page\"\"\"\n",
    "    \n",
    "    try:\n",
    "        last_p_elements = driver.find_elements(By.CSS_SELECTOR, \"p.pagination_PageNumberText__zy_hr\")\n",
    "        return int([p.text for p in last_p_elements][-1])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error finding last page: {e}\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c710e2-9d0b-4648-b430-683d7f699cee",
   "metadata": {},
   "source": [
    "##### 3. Review 요소 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de81234-f365-4da7-94ed-5197ce36b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_details(li_element):\n",
    "    \n",
    "    \"\"\" Extract Review Deatails \"\"\"\n",
    "    \n",
    "    review_dict = {}\n",
    "    try:\n",
    "        ############################# 각 요소 ############################# \n",
    "        date = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'timestamp_reviewDate__dsF9n'))).text\n",
    "        rating = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'review-rating_ratingLabel__0_Hk9'))).text\n",
    "        one_line_review = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'heading_Heading__BqX5J.heading_Level3__X81KK'))).text\n",
    "        job = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'review-avatar_avatarLabel__P15ey'))).text\n",
    "        history = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'text-with-icon_TextWithIcon__5ZZqT'))).text\n",
    "        \n",
    "        try:\n",
    "            region = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'review-avatar_tagsContainer__9NCNs'))).text.split('\\n')[1]\n",
    "        except:\n",
    "            region=None\n",
    "        \n",
    "        pros = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test=\"review-text-PROS\"]'))).text\n",
    "        cons = WebDriverWait(li_element, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test=\"review-text-CONS\"]'))).text\n",
    "    \n",
    "        try:\n",
    "            show_more_button_class_nm = 'expand-button_ExpandButton__Wevvg'\n",
    "            show_more_button = WebDriverWait(li_element, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, show_more_button_class_nm))\n",
    "            )\n",
    "            show_more_button.click()\n",
    "    \n",
    "            feedback = WebDriverWait(li_element, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test=\"review-text-FEEDBACK\"]'))\n",
    "            ).text\n",
    "        except:\n",
    "            feedback = None\n",
    "        \n",
    "        review_dict.update({\n",
    "            'Date': date,\n",
    "            'Job': job,\n",
    "            'History': history,\n",
    "            'Region': region if region else None,\n",
    "            'One_line_review': one_line_review,\n",
    "            'Rating': rating,\n",
    "            'Pros': pros,\n",
    "            'Cons': cons,\n",
    "            'Feedback': feedback# if feedback else None,\n",
    "        })\n",
    "\n",
    "        ############################# Sub Rating ############################# \n",
    "        try:\n",
    "            rating_element = li_element.find_element(By.CLASS_NAME, 'review-details-bar_reviewRatingAndFeaturedContainer__J8iG9')\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # ActionChains로 마우스를 이동시켜서 숨겨진 요소 표시\n",
    "            ActionChains(driver).move_to_element(rating_element).perform()\n",
    "            tooltip = WebDriverWait(driver, 5).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, '[data-test=\"review-subratings-tooltip\"]'))\n",
    "            )\n",
    "            # 숨겨진 요소의 요소 전부 값 가져오기\n",
    "            tooltip_html = tooltip.get_attribute(\"innerHTML\")\n",
    "            soup = BeautifulSoup(tooltip_html, 'html.parser')\n",
    "            \n",
    "            # 각 항목을 포함하는 div를 찾음\n",
    "            sub_ratings = soup.find_all('div', class_='review-rating_subRating__0Q_Z0')\n",
    "            \n",
    "            # 각 항목별로 점수 계산\n",
    "            for rating in sub_ratings:\n",
    "                # 항목 이름 가져오기\n",
    "                category = rating.find('span', class_='review-rating_subRatingText__Wn3AL').text.strip()\n",
    "                # --outline-percentage가 0%인 별만 카운트\n",
    "                stars = len(rating.find_all('div', style=\"--outline-percentage: 0%;\"))# 별 개수를 점수로 계산\n",
    "                review_dict[category] = stars\n",
    "                \n",
    "        except Exception:\n",
    "            pass;\n",
    "\n",
    "        ############################# Check List #############################\n",
    "        try:\n",
    "            check_list = li_element.find_elements(By.CLASS_NAME, 'review-details_experienceContainer__2W06X')\n",
    "\n",
    "            # 각 요소의 전체 HTML 출력\n",
    "            for element in check_list:\n",
    "                html_content = element.get_attribute(\"outerHTML\")\n",
    "                soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "                # 클래스 마지막 부분에 따른 값 매핑 딕셔너리\n",
    "                class_value_map = {\n",
    "                    'LGHYG': 'V',\n",
    "                    'BCbQd': 'empty',\n",
    "                    'jmOo8': '-',\n",
    "                    '0GqA8': 'X'\n",
    "                }\n",
    "\n",
    "                # 각 span 요소의 텍스트와 해당 클래스명 끝자리에 따른 값 저장\n",
    "                for span in soup.find_all('span'):\n",
    "                    # span 텍스트 가져오기\n",
    "                    span_text = span.text.strip()\n",
    "                    # 부모 div 요소의 마지막 클래스명 부분 가져오기\n",
    "                    parent_div = span.find_parent('div')\n",
    "                    last_class_part = parent_div['class'][-1].split('_')[-1]\n",
    "                    # 매핑된 값을 result 딕셔너리에 추가\n",
    "                    review_dict[span_text] = class_value_map.get(last_class_part, 'Unknown')\n",
    "        \n",
    "        except Exception:\n",
    "            pass;\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting review details: {e}\")\n",
    "    \n",
    "    return review_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4a4e9-8736-4046-96ee-c72e0e2d2ee7",
   "metadata": {},
   "source": [
    "##### 4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda87d89-e6b2-4e74-8172-f71723c794b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Filtering 함수\n",
    "def apply_filtering(driver):\n",
    "\n",
    "    \"\"\" Filtering Clear \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Filtering 버튼 상위 div XPath\n",
    "        parent_div_xpath = '//*[@id=\"__next\"]/div[2]/div/main/div/div[6]/div[4]/div[1]'#/div'\n",
    "        \n",
    "        # 상위 div 요소 찾기\n",
    "        parent_div = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, parent_div_xpath))\n",
    "        )\n",
    "        # 상위 div 내 하위 버튼 찾기\n",
    "        filtering_button = parent_div.find_element(By.TAG_NAME, 'button')\n",
    "        filtering_button.click()\n",
    "        time.sleep(5)\n",
    "        # filtering_button = WebDriverWait(parent_div, 10).until(\n",
    "        #     EC.element_to_be_clickable((By.TAG_NAME, 'button'))\n",
    "        # )\n",
    "        # filtering_button.click()\n",
    "\n",
    "        # Clear 버튼 상위 div XPath\n",
    "        parent_div_clear_path = '//*[@id=\"__next\"]/div[2]/div/main/div/div[6]/div[4]/div[1]/div/div/div'\n",
    "        parent_clear_div = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, parent_div_clear_path))\n",
    "        )\n",
    "        # 상위 div 내 하위 버튼 찾기\n",
    "        clear_button_class_nm = 'button_Button__MlD2g.button-base_Button__knLaX'\n",
    "        clear_button = parent_clear_div.find_element(By.CLASS_NAME, clear_button_class_nm)\n",
    "\n",
    "        # ActionChains로 Clear 버튼 클릭\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(clear_button).click().perform()\n",
    "        time.sleep(5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during button click process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7133f8-55be-462f-ae82-350c6e8f69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering 함수\n",
    "def apply_filtering(driver):\n",
    "\n",
    "    \"\"\" Filtering Clear \"\"\"\n",
    "\n",
    "    parent_div_xpath = '//*[@id=\"__next\"]/div[2]/div/main/div/div[6]/div[4]/div[1]'#/div'\n",
    "    \n",
    "    # 상위 div 요소 찾기\n",
    "    parent_div = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, parent_div_xpath))\n",
    "    )\n",
    "    # 상위 div 내 하위 버튼 찾기\n",
    "    filtering_button = parent_div.find_element(By.TAG_NAME, 'button')\n",
    "    filtering_button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Clear 버튼 상위 div XPath\n",
    "    parent_div_clear_path = '//*[@id=\"__next\"]/div[2]/div/main/div/div[6]/div[4]/div[1]/div/div/div'\n",
    "    parent_clear_div = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, parent_div_clear_path))\n",
    "    )\n",
    "    # 상위 div 내 하위 버튼 찾기\n",
    "    clear_button_class_nm = 'button_Button__MlD2g.button-base_Button__knLaX'\n",
    "    clear_button = parent_clear_div.find_element(By.CLASS_NAME, clear_button_class_nm)\n",
    "\n",
    "    # ActionChains로 Clear 버튼 클릭\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(clear_button).click().perform()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55b15f-5d5d-41bb-8354-945005523b9b",
   "metadata": {},
   "source": [
    "##### 5. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806c9e6b-601b-4b41-91d6-23f4525dfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(company_list):\n",
    "    global review_df, result_df, complete_company_list, filtering_fail_list\n",
    "    review_df = pd.DataFrame()\n",
    "    result_df = pd.DataFrame()\n",
    "    # complete_company =[]\n",
    "    # filtering_fail_list=[]\n",
    "    \n",
    "    for company in company_list:\n",
    "        print(f\"Processing company: {company}\")\n",
    "        file_name = f\"reviews_{company}.csv\"\n",
    "        # complete_company_list.append(company)\n",
    "        \n",
    "        review_origin_url = get_search_url(company)\n",
    "        driver.get(review_origin_url)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, link_event_time).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # 예: 'body' 태그가 로드될 때까지 대기\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(\"페이지 로드가 시간 내 완료되지 않았습니다.\")\n",
    "\n",
    "        # Filtering 처리\n",
    "        try:\n",
    "            apply_filtering(driver)\n",
    "        except:\n",
    "            with open('filtering_fail_list.pickle', 'rb') as f: # Read\n",
    "                filtering_fail_list = pickle.load(f)\n",
    "            filtering_fail_list.append(company) # Append\n",
    "            \n",
    "            with open(\"filtering_fail_list.pickle\",\"wb\") as f: # Write\n",
    "                pickle.dump(filtering_fail_list, f)\n",
    "            print('filterling button not found')\n",
    "            \n",
    "        # last page search\n",
    "        last_page = get_last_page()\n",
    "        print('last page:', last_page)\n",
    "\n",
    "        iteration_count = 0\n",
    "        for page in tqdm(range(1, last_page + 1)):\n",
    "            iteration_count+=1\n",
    "            \n",
    "            if page > 1:\n",
    "                review_url = review_origin_url.replace('.htm', f'_P{page}.htm')\n",
    "                driver.get(review_url)\n",
    "                time.sleep(link_event_time)\n",
    "            else:\n",
    "                # driver.get(review_origin_url)\n",
    "                # time.sleep(link_event_time)\n",
    "                pass;\n",
    "\n",
    "            try:\n",
    "                li_elements = driver.find_elements(By.XPATH, '//*[@id=\"ReviewsFeed\"]/ol/li')\n",
    "                for li_element in li_elements:\n",
    "                    review_dict = extract_review_details(li_element)\n",
    "                    review_dict['Company'] = company\n",
    "                    review_df = pd.concat([review_df, pd.DataFrame([review_dict])], ignore_index=True)\n",
    "\n",
    "                if iteration_count%100:\n",
    "                    review_df.to_csv(f'tmp_company_review/{file_name}', index=False)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing reviews on page {page} for {company}: {e}\")\n",
    "        \n",
    "        result_df = pd.concat([result_df, review_df], ignore_index=True)\n",
    "        result_df.to_csv('company_review_data/complete_'+file_name, index=False)\n",
    "        \n",
    "        with open('complete_company_list.pickle', 'rb') as f:\n",
    "            complete_company_list = pickle.load(f)\n",
    "        complete_company_list.append(company)\n",
    "        \n",
    "        with open(\"complete_company_list.pickle\",\"wb\") as f:\n",
    "            pickle.dump(complete_company_list, f)\n",
    "        \n",
    "        print(f\"{company} complete !\")\n",
    "\n",
    "    print(\"Scraping complete\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2932c8bf-5145-44d0-94ec-928e803a205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_csv('company_review_summary.csv')\n",
    "company_df = company_df[company_df['review']>500].sort_values('review').reset_index(drop=True)\n",
    "company_list = company_df['company'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4dceca8-49e4-40b8-8310-4cfa3896da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('complete_company_list.pickle', 'rb') as f:\n",
    "    complete_company_list = pickle.load(f)\n",
    "extra_companies = [company for company in company_list if company not in complete_company_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c82bccb5-9f7b-47eb-a32d-7decf4e842ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lithia Motors, Inc.',\n",
       " 'Inter-American Development Bank',\n",
       " 'Opendoor Technologies, Inc.',\n",
       " 'Valvoline, Inc.',\n",
       " 'News Corp.',\n",
       " 'The New York Times Co.',\n",
       " 'Ingersoll Rand, Inc.',\n",
       " 'Teck Resources Limited',\n",
       " 'Zoetis, Inc.',\n",
       " 'Mettler-Toledo International, Inc.',\n",
       " 'Mohawk Industries, Inc.',\n",
       " 'Guidewire Software, Inc.',\n",
       " 'Equity Residential',\n",
       " 'Nasdaq, Inc.',\n",
       " 'Hasbro, Inc.',\n",
       " 'Sensata Technologies Holding Plc',\n",
       " 'LKQ Corp.',\n",
       " 'Sun Life Financial, Inc.',\n",
       " 'Polaris Inc.',\n",
       " 'Kinder Morgan, Inc.',\n",
       " 'Ontario Power Generation, Inc.',\n",
       " 'Celestica, Inc.',\n",
       " 'TD SYNNEX Corp.',\n",
       " 'Avantor, Inc.',\n",
       " 'Xylem, Inc.',\n",
       " 'Ball Corp.',\n",
       " 'American Tower Corp.',\n",
       " 'Bio-Rad Laboratories, Inc.',\n",
       " 'Waters Corp.',\n",
       " 'Crown Castle, Inc.',\n",
       " 'Dentsply Sirona, Inc.',\n",
       " 'AvalonBay Communities, Inc.',\n",
       " 'Public Storage',\n",
       " 'Regeneron Pharmaceuticals, Inc.',\n",
       " 'Lam Research Corp.',\n",
       " 'Trimble, Inc.',\n",
       " 'Avnet, Inc.',\n",
       " 'BorgWarner, Inc.',\n",
       " 'AutoNation, Inc.',\n",
       " 'Henry Schein, Inc.',\n",
       " 'Canadian National Railway Co.',\n",
       " 'Air Products & Chemicals, Inc.',\n",
       " 'Cencora, Inc.',\n",
       " 'Charles River Laboratories International, Inc.',\n",
       " 'The Hershey Co.',\n",
       " 'Zebra Technologies Corp.',\n",
       " 'Enbridge, Inc.',\n",
       " 'Akamai Technologies, Inc.',\n",
       " 'Palo Alto Networks, Inc.',\n",
       " 'Massachusetts Mutual Life Insurance Co.',\n",
       " 'ManpowerGroup, Inc.',\n",
       " 'Agilent Technologies, Inc.',\n",
       " 'National Instruments Corp.',\n",
       " 'Arrow Electronics, Inc.',\n",
       " 'Ryder System, Inc.',\n",
       " 'Stantec, Inc.',\n",
       " 'Principal Financial Group, Inc.',\n",
       " 'Keysight Technologies, Inc.',\n",
       " 'Iron Mountain, Inc.',\n",
       " 'Seagate Technology Holdings Plc',\n",
       " 'Illumina, Inc.',\n",
       " 'Cadence Design Systems, Inc.',\n",
       " 'GLOBALFOUNDRIES, Inc.',\n",
       " 'The Western Union Co.',\n",
       " \"Carter's, Inc.\",\n",
       " 'Colliers International Group, Inc.',\n",
       " 'Lear Corp.',\n",
       " 'Williams-Sonoma, Inc.',\n",
       " 'The Williams Cos., Inc.',\n",
       " \"O'Reilly Automotive, Inc.\",\n",
       " 'Synopsys, Inc.',\n",
       " 'Jabil, Inc.',\n",
       " 'International Bank for Reconstruction & Development',\n",
       " 'J.B. Hunt Transport Services, Inc.',\n",
       " 'Avis Budget Group, Inc.',\n",
       " 'W.W. Grainger, Inc.',\n",
       " 'General Mills, Inc.',\n",
       " 'Western Digital Corp.',\n",
       " 'CDW Corp.',\n",
       " 'Cardinal Health, Inc.',\n",
       " 'Applied Materials, Inc.',\n",
       " 'Advanced Micro Devices, Inc.',\n",
       " 'Advance Auto Parts, Inc.',\n",
       " 'Motorola Solutions, Inc.',\n",
       " 'L3Harris Technologies, Inc.',\n",
       " 'Electronic Arts, Inc.',\n",
       " 'Elevance Health, Inc.',\n",
       " 'McKesson Corp.',\n",
       " 'TELUS International (CDA), Inc.',\n",
       " 'NVIDIA Corp.',\n",
       " 'Ecolab, Inc.',\n",
       " 'AutoZone, Inc.',\n",
       " 'The Cigna Group',\n",
       " 'Flex Ltd.',\n",
       " 'WSP Global, Inc.',\n",
       " 'Jacobs Engineering Group, Inc.',\n",
       " 'CarMax, Inc.',\n",
       " 'HP, Inc.',\n",
       " 'QUALCOMM, Inc.',\n",
       " 'Pfizer Inc.',\n",
       " 'Adobe, Inc.',\n",
       " 'Amdocs Ltd.',\n",
       " 'Jones Lang LaSalle, Inc.',\n",
       " 'Thermo Fisher Scientific, Inc.',\n",
       " 'Robert Half, Inc.',\n",
       " 'UnitedHealth Group, Inc.',\n",
       " 'Salesforce, Inc.',\n",
       " 'PepsiCo, Inc.',\n",
       " 'Automatic Data Processing, Inc.',\n",
       " 'DXC Technology Co.',\n",
       " 'Cisco Systems, Inc.',\n",
       " \"Lowe's Companies, Inc.\",\n",
       " 'The Home Depot, Inc.',\n",
       " 'Oracle Corp.',\n",
       " 'Microsoft Corp.',\n",
       " 'Cognizant Technology Solutions Corp.',\n",
       " 'International Business Machines Corp.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_companies\n",
    "# company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82d05b-e73a-44e8-b76d-b3b3d89a9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing company: Lithia Motors, Inc.\n",
      "last page: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████▉                         | 30/88 [2:48:02<5:51:18, 363.42s/it]"
     ]
    }
   ],
   "source": [
    "company_review_df = scrape_reviews(extra_companies)\n",
    "print(\"All reviews saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921423fd-b15f-437e-92a4-aa9fae29aa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e304da-75e1-49e2-b661-f21b62184333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
